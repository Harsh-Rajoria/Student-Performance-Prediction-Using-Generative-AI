# -*- coding: utf-8 -*-
"""StudentPerformance(GEN-A.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cSLmpTcHY5eD1quG_MNl0M2EbNAmnezd

ğŸ§© Module 1: Student Performance Prediction (G3)

ğŸ”¥ What we did:
	â€¢	Collected UCI Student Performance Dataset (studentsâ€™ data).
	â€¢	Selected important features like:
	â€¢	studytime
	â€¢	failures
	â€¢	absences
	â€¢	parent education, etc.
	â€¢	Trained a RandomForestRegressor model to predict final grade (G3).

ğŸ§  Why we did it:
	â€¢	Prediction helps to identify struggling students early.
	â€¢	Random Forest was chosen because:
	â€¢	Easy to train.
	â€¢	Works well on small datasets like student profiles.
	â€¢	Handles mixed features (numerical + categorical).

â¸»

ğŸ§© Module 2: Synthetic Student Data Generation

ğŸ”¥ What we did:
	â€¢	Used SDV (Synthetic Data Vault) or Gemini AI to generate fake but realistic student profiles.
	â€¢	Created extra student data (more training/testing).

ğŸ§  Why we did it:
	â€¢	Real datasets are limited â” difficult to test large apps.
	â€¢	Synthetic data helps in:
	â€¢	Expanding training data.
	â€¢	Privacy â” No real student names/marks used.
	â€¢	Better model generalization.

â¸»

ğŸ§© Module 3: Academic Assistant Chatbot

ğŸ”¥ What we did:
	â€¢	Built a chatbot using Gemini (Google AI) and fallback OpenAI GPT-3.5.
	â€¢	Students could ask:
	â€¢	â€œHow to improve English?â€
	â€¢	â€œGive a study planâ€
	â€¢	â€œMotivate me to studyâ€

ğŸ§  Why we did it:
	â€¢	Students need more than prediction â” they need guidance.
	â€¢	Generative AI feels like a human academic mentor:
	â€¢	Motivates students.
	â€¢	Makes study plans.
	â€¢	Answers academic questions.

â¸»

ğŸ§© Module 4: Academic Assistant Full Web App (Streamlit)

ğŸ”¥ What we did:
	â€¢	Built a Streamlit app where:
	â€¢	Students upload their profile (CSV).
	â€¢	AI predicts G3.
	â€¢	AI generates personalized study plan.
	â€¢	Weekly checklist created.
	â€¢	Hindi translation for non-English speakers.
	â€¢	Free chat box for any academic question.

ğŸ§  Why we did it:
	â€¢	Apps are needed for students/teachers who donâ€™t know coding.
	â€¢	Streamlit was used because:
	â€¢	Easy to build web apps in Python.
	â€¢	Instant deployment (on Colab using ngrok).

â¸»

ğŸ§© Module 5: Performance Logging and Progress Tracker

ğŸ”¥ What we did:
	â€¢	After getting a study plan, students can log their weekly work:
	â€¢	Tasks completed each week.
	â€¢	Reflections: What went well / What went wrong.
	â€¢	Goals for next week.
	â€¢	Saved this into a CSV (performance_log.csv).
	â€¢	Built graphs:
	â€¢	Task completion pie charts.
	â€¢	Reflection summaries.
	â€¢	Monthly progress tracking.

ğŸ§  Why we did it:
	â€¢	Tracking builds consistency â” small weekly improvements = huge final improvement.
	â€¢	Students can visualize their progress (not just see marks).

â¸»

ğŸ§© Module 6: Leaderboards and Monthly Progress

ğŸ”¥ What we did:
	â€¢	Created a Leaderboard:
	â€¢	Show top students based on predicted G3.
	â€¢	Show consistency streaks (how many continuous weeks student logged work).
	â€¢	Generated Monthly Progress Reports:
	â€¢	G3 trend month-by-month.
	â€¢	Downloadable PDF reports.

ğŸ§  Why we did it:
	â€¢	Healthy competition motivates students.
	â€¢	Monthly view helps students and teachers plan interventions.
	â€¢	PDF download allows students to print and submit reports.

â¸»

#1. Grade Predictor With Explanation
"""

!pip install ucimlrepo scikit-learn pandas google-generativeai
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from ucimlrepo import fetch_ucirepo
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import google.generativeai as genai

# ----------------------------------
# 1. Load the dataset from UCI Repo
# ----------------------------------
from ucimlrepo import fetch_ucirepo
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Fetch dataset from UCI ML Repo
student = fetch_ucirepo(id=320)

# Features and targets
X = student.data.features
#y = student.data.targets.squeeze()  # 'G3' is the final grade
y = student.data.targets['G3']

# Encode categorical variables
label_encoders = {}
for col in X.select_dtypes(include='object').columns:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col])
    label_encoders[col] = le

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ----------------------------------
# 2. Train a Random Forest Regressor
# ----------------------------------
from sklearn.ensemble import RandomForestRegressor  # Import RandomForestRegressor
from sklearn.metrics import mean_squared_error # Import mean_squared_error

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"ğŸ“Š Mean Squared Error: {mse:.2f}")

!pip install xgboost
from xgboost import XGBRegressor

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from xgboost import XGBRegressor
import pandas as pd

# Load your dataset (example with UCI fetch_ucirepo)
# (X, y should already be prepared.)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ”¥ Train XGBoost model
model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluate
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.2f}")

from xgboost import plot_importance
import matplotlib.pyplot as plt

plot_importance(model)
plt.show()

"""XGBoost Hyper Parameter Tuning"""

from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV

xgb = XGBRegressor(random_state=42)

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.8, 1.0],
}

grid_search = GridSearchCV(
    estimator=xgb,
    param_grid=param_grid,
    cv=6,
    scoring='neg_mean_squared_error',
    verbose=2,
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)
print("Lowest MSE:", -grid_search.best_score_)

best_xgb = grid_search.best_estimator_
y_pred = best_xgb.predict(X_test)

# ----------------------------------
# 3. Select a test sample
# ----------------------------------
import numpy as np
import pandas as pd

sample_idx = np.random.randint(0, len(X_test))
sample = X_test.iloc[sample_idx]
sample_df = pd.DataFrame([sample])
# Predict and safely extract a scalar float
raw_pred = model.predict(sample_df)
pred = float(raw_pred[0])

# Force correct scalar extraction: assumes batch size = 1
#if isinstance(raw_pred, np.ndarray) and raw_pred.shape == (1,):
 #   pred = float(raw_pred[0])
#else:
 #   raise ValueError(f"Unexpected prediction shape: {raw_pred.shape}")

# ----------------------------------
# 4. Safe stringify for Gemini prompt
# ----------------------------------
# 4. Safe stringify for Gemini prompt (force everything to plain string)
#sample_dict = sample.to_dict()

#sample_clean_pairs = []
#for k, v in sample_dict.items():
 #   try:
  #      # Flatten numpy types or arrays
   #     if isinstance(v, (np.generic, np.ndarray)):
    #        v = np.asscalar(np.array(v)) if np.array(v).size == 1 else v.tolist()
     #   sample_clean_pairs.append(f"{k}: {v}")
    #except Exception:
     #   sample_clean_pairs.append(f"{k}: ConversionError")

#sample_clean_str = "\n".join(sample_clean_pairs)
#sample_clean_str = "\n".join([f"{k}: {safe_stringify(v)}" for k, v in sample_dict.items()])

def safe_stringify(val):
    try:
        if isinstance(val, (np.generic, np.ndarray)):
            return str(np.array(val).flatten()[0])
        else:
            return str(val)
    except Exception:
        return "ConversionError"

sample_dict = sample.to_dict()
sample_clean_str = "\n".join([f"{k}: {safe_stringify(v)}" for k, v in sample_dict.items()])

# ----------------------------------
# 5. Prepare Gemini prompt
# ----------------------------------
import google.generativeai as genai

genai.configure(api_key="Paste your API key")  # Replace with your real Gemini API key
model_gen = genai.GenerativeModel('gemini-1.5-flash')

prompt = (
    "ğŸ“˜ Student Performance Prediction Explanation\n\n"
    "Student Profile:\n" +
    sample_clean_str + "\n\n" +
    f"Predicted Final Grade (G3): {pred:.2f}\n\n"
    "Explain this prediction. Consider factors like study time, failures, absences, and parental education."
)

# ----------------------------------
# 6. Generate explanation with Gemini
# ----------------------------------
response = model_gen.generate_content(prompt)
#print(response)

# ----------------------------------
# 7. Output
# ----------------------------------
print("\nğŸ“˜ Gemini Explanation:\n")
print(response.text)

"""#2. Synthetic Student Data Generator"""

# Install necessary packages
!pip install sdv ucimlrepo scikit-learn

from ucimlrepo import fetch_ucirepo
from sdv.single_table import GaussianCopulaSynthesizer
from sdv.metadata import SingleTableMetadata
from sklearn.preprocessing import LabelEncoder
import pandas as pd

# -------------------------
# 1. Fetch dataset from UCI
# -------------------------
student = fetch_ucirepo(id=320)  # UCI Student Performance dataset

# Combine features and G3 target into one DataFrame
df = pd.concat([student.data.features, student.data.targets['G3']], axis=1)

# -------------------------
# 2. Encode categorical columns
# -------------------------
df_encoded = df.copy()
label_encoders = {}
for col in df_encoded.select_dtypes(include='object').columns:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])
    label_encoders[col] = le

# -------------------------
# 3. Define metadata
# -------------------------
metadata = SingleTableMetadata()
metadata.detect_from_dataframe(data=df_encoded)

# -------------------------
# 4. Train the synthesizer
# -------------------------
synthesizer = GaussianCopulaSynthesizer(metadata)
synthesizer.fit(df_encoded)

# -------------------------
# 5. Generate synthetic data
# -------------------------
synthetic_data = synthesizer.sample(num_rows=100)

# -------------------------
# 6. Decode synthetic categorical columns
# -------------------------
for col, le in label_encoders.items():
    synthetic_data[col] = le.inverse_transform(
        synthetic_data[col].clip(0, len(le.classes_) - 1).astype(int)
    )

# -------------------------
# 7. View output
# -------------------------
print("ğŸ§‘â€ğŸ“ Synthetic Student Data (Sample):\n")
print(synthetic_data.head())

#same thing but using gemini prompt to create synthetic students
import google.generativeai as genai

genai.configure(api_key="Paste your API key")
model_gen = genai.GenerativeModel('gemini-1.5-pro-latest')

prompt = """
Generate 3 fictional student profiles based on the following format:
- sex (M/F)
- age (15-22)
- address (U/R)
- famsize (LE3/GT3)
- studytime (1 to 4)
- failures (0 to 3)
- absences (0 to 30)
- G3 (final grade, 0 to 20)

Each student should look realistic and reflect how these values might affect G3.
"""

response = model_gen.generate_content(prompt)
print(response.text)

"""#3. Intervention Plan Generator"""

# Install required packages if not already installed
# !pip install google-generativeai ucimlrepo scikit-learn pandas

import google.generativeai as genai
from ucimlrepo import fetch_ucirepo
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import numpy as np

# ğŸ”‘ Set your Gemini API key
genai.configure(api_key="Paste your API key")  # Replace with your actual key
model = genai.GenerativeModel("gemini-1.5-flash")

# ----------------------------------------
# STEP 1: Fetch and prepare student dataset
# ----------------------------------------
student_data = fetch_ucirepo(id=320)
df = pd.concat([student_data.data.features, student_data.data.targets['G3']], axis=1)

# Encode categorical features
df_encoded = df.copy()
label_encoders = {}
for col in df_encoded.select_dtypes(include='object').columns:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])
    label_encoders[col] = le

# ----------------------------------------
# STEP 2: Select a sample student profile
# ----------------------------------------
# You can use a real one or replace this with synthetic data
student = df.iloc[0]  # Change the index to try different students
student_clean_str = "\n".join([f"{k}: {v}" for k, v in student.to_dict().items()])

# ----------------------------------------
# STEP 3: Generate personalized intervention plan
# ----------------------------------------
plan_prompt = f"""
A student has the following academic and personal profile:

{student_clean_str}

They received a final grade (G3) of {student['G3']}/20.

Based on this profile, generate a personalized study and improvement plan to help them improve their performance.
Include actionable suggestions based on study time, absences, family background, and motivation.
Also provide motivational advice that encourages the student without judgment.
"""

plan_response = model.generate_content(plan_prompt)
print("ğŸ“˜ Personalized Student Improvement Plan:\n")
print(plan_response.text)

# ----------------------------------------
# STEP 4: Generate teacher support report
# ----------------------------------------
teacher_prompt = f"""
You are a teacher reviewing a student with this profile:

{student_clean_str}

The student received a final grade (G3) of {student['G3']}/20.

As a teacher, how can you best support this student?
Consider study time, failures, absences, parental education, and motivation levels.
Offer practical suggestions for engagement, encouragement, and intervention.
"""

teacher_response = model.generate_content(teacher_prompt)
print("\nğŸ‘©â€ğŸ« Teacher Support Report:\n")
print(teacher_response.text)

# ----------------------------------------
# STEP 5: Generate weekly checklist for the student
# ----------------------------------------
checklist_prompt = f"""
Create a weekly checklist plan for a student with the following profile:

{student_clean_str}

The goal is to improve their academic performance in a balanced, achievable way.
Include tasks related to study time, class attendance, revision, health, and motivation.
Make it simple and organized by days (Mon to Sun).
"""

checklist_response = model.generate_content(checklist_prompt)
print("\nğŸ—“ï¸ Weekly Study Checklist:\n")
print(checklist_response.text)

# ----------------------------------------
# STEP 6: Interactive Chatbot (Student Assistant)
# ----------------------------------------

print("\nğŸ¤– Academic Assistant Chatbot (type 'exit' to stop):")

while True:
    user_input = input("ğŸ§‘ Ask the study assistant: ")
    if user_input.lower() == "exit":
        print("ğŸ‘‹ Chat ended.")
        break

    # Gemini expects a single string or 'parts'
    prompt = f"""
You are an academic assistant.
The student says: "{user_input}"

Give a helpful, step-by-step answer. Use simple English.
Encourage the student and give motivation if needed.
"""

    try:
        response = model.generate_content(prompt)
        print("\nğŸ¤– Assistant:", response.text)
    except Exception as e:
        print("âš ï¸ Error:", e)

"""#4. Conversational Assistant"""

!pip install streamlit pyngrok google-generativeai openai pandas
!pip install openai==0.28

!pkill streamlit
!pkill ngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import streamlit as st
# import pandas as pd
# import google.generativeai as genai
# import openai
# import time
# 
# # ----------------------------
# # ğŸ” API Configuration
# # ----------------------------
# genai.configure(api_key="Paste your API key")  # Replace with Gemini key
# openai.api_key = "Paste your API key"          # Replace with OpenAI key
# 
# # ----------------------------
# # ğŸ¤– Model Wrapper with Fallback
# # ----------------------------
# def generate_response(prompt):
#     try:
#         gemini_model = genai.GenerativeModel("models/gemini-1.5-flash")
#         return gemini_model.generate_content(prompt).text
#     except Exception as gemini_error:
#         print("âš ï¸ Gemini failed. Falling back to OpenAI...")
#         try:
#             response = client.chat.completions.create(
#                 model="gpt-3.5-turbo",
#                 messages=[{"role": "user", "content": prompt}]
#             )
#             return response.choices[0].message.content
#         except Exception as openai_error:
#             return f"âŒ Both models failed.\nGemini: {gemini_error}\nOpenAI: {openai_error}"
# 
# # ----------------------------
# # ğŸ¨ Streamlit Page Settings
# # ----------------------------
# st.set_page_config(page_title="ğŸ“ Academic Assistant", page_icon="ğŸ§ ")
# st.title("ğŸ“ Academic Assistant Chatbot")
# st.markdown("Ask questions or upload a student profile to receive personalized guidance!")
# 
# # ----------------------------
# # ğŸ“¤ Upload Student Profile CSV
# # ----------------------------
# profile = st.file_uploader("Upload a CSV file with student profiles (e.g., from UCI dataset):", type=["csv"])
# if profile:
#     df = pd.read_csv(profile)
#     st.success("File uploaded successfully!")
#     selected_index = st.number_input("Select Student Index", min_value=0, max_value=len(df)-1, step=1)
#     student = df.iloc[selected_index]
#     student_str = "\n".join([f"{k}: {v}" for k, v in student.to_dict().items()])
# 
#     with st.expander("ğŸ“˜ Personalized Plan"):
#         plan_prompt = f"""
# You are a learning assistant.
# A student has the following profile:
# 
# {student_str}
# 
# Generate a personalized academic improvement plan for them.
# """
#         plan_text = generate_response(plan_prompt)
#         st.markdown(plan_text)
# 
#     with st.expander("ğŸ—“ï¸ Weekly Checklist"):
#         checklist_prompt = f"""
# Based on this student profile:
# 
# {student_str}
# 
# Create a simple Monday-to-Sunday weekly checklist to help them improve.
# """
#         checklist_text = generate_response(checklist_prompt)
#         st.markdown(checklist_text)
# 
#     with st.expander("ğŸŒ Translate to Hindi"):
#         translate_prompt = f"""
# Translate this academic improvement plan into Hindi:
# 
# {plan_text}
# """
#         hindi_text = generate_response(translate_prompt)
#         st.markdown(hindi_text)
# 
# # ----------------------------
# # ğŸ’¬ Freeform Chatbot Section
# # ----------------------------
# st.markdown("---")
# st.subheader("ğŸ’¬ Chat with Academic Assistant")
# 
# if "messages" not in st.session_state:
#     st.session_state.messages = []
# 
# user_input = st.chat_input("Type your academic question here...")
# if user_input:
#     chat_prompt = f"""
# You are a helpful academic assistant.
# Student says:
# "{user_input}"
# 
# Reply clearly in simple English. Give helpful and motivational tips.
# """
#     reply = generate_response(chat_prompt)
#     st.session_state.messages.append(("user", user_input))
#     st.session_state.messages.append(("assistant", reply))
# 
# for role, msg in st.session_state.messages:
#     with st.chat_message(role):
#         st.markdown(msg)
#

from pyngrok import ngrok
import time

# Kill previous processes
!pkill streamlit

# Set your valid ngrok token
ngrok.set_auth_token("Paste your token from NGROK")

# âœ… Corrected tunnel connection
public_url = ngrok.connect(addr="8501", proto="http")
print("ğŸŒ Streamlit app is live at:", public_url)

# Run Streamlit
!streamlit run app.py &>/content/logs.txt &
time.sleep(5)

"""#5. Report Card Narrator"""

!pip install streamlit pyngrok google-generativeai openai pandas
!pip install openai==0.28
!pip install FPDF

!ngrok http 8501

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import streamlit as st
# import pandas as pd
# import google.generativeai as genai
# import openai
# import time
# import os
# from datetime import datetime
# import matplotlib.pyplot as plt
# import random
# from io import BytesIO
# from fpdf import FPDF
# 
# # ----------------------------
# # ğŸ” API Configuration
# # ----------------------------
# genai.configure(api_key="Paste your API key")
# openai.api_key = "Paste your API key"
# 
# # ----------------------------
# # ğŸ¤– Model Wrapper with Fallback
# # ----------------------------
# def generate_response(prompt):
#     try:
#         gemini_model = genai.GenerativeModel("models/gemini-1.5-flash")
#         return gemini_model.generate_content(prompt).text
#     except Exception as gemini_error:
#         print("âš ï¸ Gemini failed. Falling back to OpenAI...")
#         try:
#             response = openai.ChatCompletion.create(
#                 model="gpt-3.5-turbo",
#                 messages=[{"role": "user", "content": prompt}]
#             )
#             return response['choices'][0]['message']['content']
#         except Exception as openai_error:
#             return f"âŒ Both models failed.\nGemini: {gemini_error}\nOpenAI: {openai_error}"
# 
# # ----------------------------
# # ğŸ¨ Streamlit Page Settings
# # ----------------------------
# st.set_page_config(page_title="ğŸ“ Academic Assistant", page_icon="ğŸ§ ")
# st.title("ğŸ“ Academic Assistant Chatbot")
# st.markdown("Ask questions or upload a student profile to receive personalized guidance!")
# 
# # ğŸ“š Motivational Quotes
# quotes = [
#     "Believe you can and you're halfway there.",
#     "Every day is a chance to get better.",
#     "Focus on progress, not perfection.",
#     "Small steps lead to big achievements.",
#     "Mistakes are proof you're trying."
# ]
# 
# # ----------------------------
# # ğŸ“¤ Upload Student Profile CSV
# # ----------------------------
# profile = st.file_uploader("Upload a CSV file with student profiles (e.g., from UCI dataset):", type=["csv"])
# if profile:
#     df = pd.read_csv(profile)
#     st.success("File uploaded successfully!")
#     selected_index = st.number_input("Select Student Index", min_value=0, max_value=len(df)-1, step=1)
#     student = df.iloc[selected_index]
#     student_str = "\n".join([f"{k}: {v}" for k, v in student.to_dict().items()])
# 
#     with st.expander("ğŸ“˜ Personalized Plan"):
#         plan_prompt = f"You are a learning assistant.\nA student has the following profile:\n{student_str}\nGenerate a personalized academic improvement plan."
#         plan_text = generate_response(plan_prompt)
#         st.markdown(plan_text)
# 
#     with st.expander("ğŸ—“ï¸ Weekly Checklist"):
#         checklist_prompt = f"Based on this student profile:\n{student_str}\nCreate a simple Monday-to-Sunday weekly checklist."
#         checklist_text = generate_response(checklist_prompt)
#         st.markdown(checklist_text)
# 
#     with st.expander("ğŸŒ Translate to Hindi"):
#         translate_prompt = f"Translate this academic improvement plan into Hindi:\n{plan_text}"
#         hindi_text = generate_response(translate_prompt)
#         st.markdown(hindi_text)
# 
#     # ----------------------------
#     # ğŸ“ˆ Module 5: Performance Logging
#     # ----------------------------
#     st.markdown("---")
#     st.header("ğŸ“ˆ Log Student Performance")
# 
#     completed_tasks = st.slider("Tasks completed today (out of 7)", 0, 7, 0)
#     reflection = st.text_area("Reflection / Notes")
#     next_week_goal = st.text_input("Goal for Next Week (e.g., 'Complete all English tasks')")
# 
#     if st.button("ğŸ“Œ Save Performance Log"):
#         g3_prompt = f"Estimate student's current final grade (G3) based on:\nProfile: {student_str}\nTasks Completed: {completed_tasks}/7\nReflection: {reflection}"
#         predicted_g3 = generate_response(g3_prompt)
# 
#         log_entry = {
#             "date": datetime.today().strftime("%Y-%m-%d"),
#             "student_index": selected_index,
#             "completed_tasks": completed_tasks,
#             "reflection": reflection,
#             "predicted_G3": predicted_g3.strip(),
#             "next_week_goal": next_week_goal
#         }
# 
#         log_file = "performance_log.csv"
#         if os.path.exists(log_file):
#             pd.DataFrame([log_entry]).to_csv(log_file, mode='a', header=False, index=False)
#         else:
#             pd.DataFrame([log_entry]).to_csv(log_file, index=False)
# 
#         st.success("Performance logged successfully!")
#         st.info(f"ğŸŒŸ Motivation for you: '{random.choice(quotes)}'")
# 
#     if os.path.exists("performance_log.csv"):
#         st.subheader("ğŸ“Š Past Logs")
#         logs = pd.read_csv("performance_log.csv")
#         student_logs = logs[logs["student_index"] == selected_index]
#         st.dataframe(student_logs)
# 
#         if not student_logs.empty:
#             st.line_chart(student_logs["predicted_G3"].apply(pd.to_numeric, errors='coerce'))
# 
#             # Pie chart for tasks
#             fig, ax = plt.subplots()
#             completed = student_logs["completed_tasks"].sum()
#             total = len(student_logs) * 7
#             labels = ['Completed', 'Missed']
#             sizes = [completed, total - completed]
#             ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
#             ax.axis('equal')
#             st.pyplot(fig)
# 
#             # Download button
#             csv_buffer = BytesIO()
#             student_logs.to_csv(csv_buffer, index=False)
#             csv_buffer.seek(0)
#             st.download_button(
#                 label="â¬‡ï¸ Download My Progress Log",
#                 data=csv_buffer,
#                 file_name=f"student_{selected_index}_log.csv",
#                 mime="text/csv"
#             )
# 
#             # Weekly analysis
#             with st.expander("ğŸ“… Weekly Insights"):
#                 logs_week = student_logs.copy()
#                 logs_week["date"] = pd.to_datetime(logs_week["date"], errors="coerce")
#                 logs_week["week"] = logs_week["date"].dt.isocalendar().week
#                 logs_week["predicted_G3"] = pd.to_numeric(logs_week["predicted_G3"], errors='coerce')
# 
#                 weekly_summary = logs_week.groupby("week").agg({
#                     "predicted_G3": "mean",
#                     "completed_tasks": "mean",
#                     "reflection": lambda x: " ".join(x),
#                     "next_week_goal": lambda x: " ".join(x)
#                 }).reset_index()
# 
#                 st.dataframe(weekly_summary)
# 
#                 for _, row in weekly_summary.iterrows():
#                     if row["predicted_G3"] < 10 or row["completed_tasks"] < 4:
#                         st.warning(f"âš ï¸ Week {int(row['week'])}: Low performance (G3: {row['predicted_G3']:.1f}, Tasks: {row['completed_tasks']:.1f})")
# 
#                 if not weekly_summary.empty:
#                     insights_prompt = f"Analyze student's weekly performance:\n{weekly_summary.to_string(index=False)}\nSummarize G3 trends, task habits, and reflections. Suggest motivational tips too."
#                     weekly_insights = generate_response(insights_prompt)
#                     st.markdown(weekly_insights)
# 
#                     if st.button("ğŸ“„ Export Weekly Report as PDF"):
#                         pdf = FPDF()
#                         pdf.add_page()
#                         pdf.set_font("Arial", size=12)
#                         pdf.multi_cell(0, 10, weekly_insights)
#                         pdf_buffer = BytesIO()
#                         pdf.output(pdf_buffer)
#                         pdf_buffer.seek(0)
#                         st.download_button(
#                             label="â¬‡ï¸ Download PDF Report",
#                             data=pdf_buffer,
#                             file_name="weekly_report.pdf",
#                             mime="application/pdf"
#                         )
# 
# # ----------------------------
# # ğŸ’¬ Freeform Chatbot Section
# # ----------------------------
# st.markdown("---")
# st.subheader("ğŸ’¬ Chat with Academic Assistant")
# 
# if "messages" not in st.session_state:
#     st.session_state.messages = []
# 
# user_input = st.chat_input("Type your academic question here...")
# if user_input:
#     chat_prompt = f"""
# You are a helpful academic assistant.
# Student says:
# "{user_input}"
# 
# Reply clearly in simple English.
# """
#     reply = generate_response(chat_prompt)
#     st.session_state.messages.append(("user", user_input))
#     st.session_state.messages.append(("assistant", reply))
# 
# for role, msg in st.session_state.messages:
#     with st.chat_message(role):
#         st.markdown(msg)

from pyngrok import ngrok
import time

# Kill previous processes
!pkill streamlit

# Set your valid ngrok token
ngrok.set_auth_token("2wWsea7TdGIpQBfDXQ599oGg4jN_3rWJdvkGYC1NNaz5A414H")

# âœ… Corrected tunnel connection
public_url = ngrok.connect(addr="8501", proto="http")
print("ğŸŒ Streamlit app is live at:", public_url)

# Run Streamlit
!streamlit run app.py &>/content/logs.txt &
time.sleep(5)

"""#6. Bias and Fairness Analysis"""

data = '''date,student_index,completed_tasks,reflection,predicted_G3,next_week_goal
2025-04-01,0,6,"Good week, need to work on maths.",15,"Practice maths problems daily."
2025-04-02,0,5,"Missed English homework.",14,"Focus more on English reading."
2025-04-01,1,7,"Perfect week!",18,"Maintain consistency."
2025-04-02,1,6,"Lost some focus midweek.",17,"Review notes daily."
2025-04-01,2,4,"Was sick, couldn't complete tasks.",10,"Catch up on missed work."
2025-04-02,2,5,"Feeling better, improved.",12,"Submit all assignments."
2025-04-03,0,7,"Very good day!",16,"Revise all chapters."
2025-04-03,1,7,"Great focus today.",19,"Start new book for literature."
2025-04-03,2,6,"Slow but steady.",13,"Increase study hours by 30 minutes."'''

with open("performance_log.csv", "w") as file:
    file.write(data)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile leaderboard.py
# 
# import streamlit as st
# import pandas as pd
# from datetime import datetime, timedelta
# import matplotlib.pyplot as plt
# from io import BytesIO
# from fpdf import FPDF
# import os
# 
# # ----------------------------
# # ğŸ¨ Streamlit Page Settings
# # ----------------------------
# st.set_page_config(page_title="ğŸ† Leaderboard & Progress Tracker", page_icon="ğŸ…")
# st.title("ğŸ† Student Leaderboard & Monthly Progress Tracker")
# 
# # ----------------------------
# # ğŸ“¥ Load Performance Log
# # ----------------------------
# log_file = "performance_log.csv"
# 
# if not os.path.exists(log_file):
#     st.error("âš ï¸ No performance logs found yet. Please log some performance first.")
# else:
#     logs = pd.read_csv(log_file)
#     logs["date"] = pd.to_datetime(logs["date"], errors="coerce")
#     logs["predicted_G3"] = pd.to_numeric(logs["predicted_G3"], errors='coerce')
# 
#     # ----------------------------
#     # ğŸ† Leaderboard Calculation
#     # ----------------------------
#     leaderboard = logs.groupby("student_index").agg({
#         "predicted_G3": "mean",
#         "completed_tasks": "mean"
#     }).reset_index()
# 
#     leaderboard = leaderboard.sort_values(by="predicted_G3", ascending=False)
#     st.subheader("ğŸ… Top Students by Final Grade (G3)")
#     st.dataframe(leaderboard)
# 
#     # Download leaderboard
#     csv_buffer = BytesIO()
#     leaderboard.to_csv(csv_buffer, index=False)
#     csv_buffer.seek(0)
#     st.download_button(
#         label="â¬‡ï¸ Download Leaderboard CSV",
#         data=csv_buffer,
#         file_name="leaderboard.csv",
#         mime="text/csv"
#     )
# 
#     # ----------------------------
#     # ğŸ“… Monthly Progress
#     # ----------------------------
#     st.subheader("ğŸ“… Monthly Progress Overview")
# 
#     logs["month"] = logs["date"].dt.to_period("M")
#     monthly_summary = logs.groupby(["student_index", "month"]).agg({
#         "predicted_G3": "mean",
#         "completed_tasks": "mean"
#     }).reset_index()
# 
#     st.dataframe(monthly_summary)
# 
#     # Optional: Chart
#     st.line_chart(monthly_summary.pivot(index="month", columns="student_index", values="predicted_G3"))
# 
#     # ----------------------------
#     # ğŸ”¥ Streak Tracker
#     # ----------------------------
#     st.subheader("ğŸ”¥ Consistency Streak Tracker")
# 
#     def longest_streak(dates):
#         dates = sorted(dates)
#         max_streak = streak = 1
#         for i in range(1, len(dates)):
#             if (dates[i] - dates[i-1]).days == 1:
#                 streak += 1
#                 max_streak = max(max_streak, streak)
#             else:
#                 streak = 1
#         return max_streak
# 
#     streaks = []
#     for sid, group in logs.groupby("student_index"):
#         streaks.append({
#             "student_index": sid,
#             "longest_streak_days": longest_streak(group["date"].tolist())
#         })
# 
#     streak_df = pd.DataFrame(streaks).sort_values(by="longest_streak_days", ascending=False)
#     st.dataframe(streak_df)
# 
#     # Download streak report
#     csv_buffer_streak = BytesIO()
#     streak_df.to_csv(csv_buffer_streak, index=False)
#     csv_buffer_streak.seek(0)
#     st.download_button(
#         label="â¬‡ï¸ Download Streak Report",
#         data=csv_buffer_streak,
#         file_name="streak_report.csv",
#         mime="text/csv"
#     )

from pyngrok import ngrok
import time

# Kill previous processes
!pkill streamlit

# Set your valid ngrok token
ngrok.set_auth_token("Paste your token from NGROK")

# âœ… Corrected tunnel connection
public_url = ngrok.connect(addr="8501", proto="http")
print("ğŸŒ Streamlit app is live at:", public_url)

# Run Streamlit
!streamlit run leaderboard.py &>/content/logs.txt &
time.sleep(5)

!streamlit run leaderboard.py

!pip install gradio --quiet

import gradio as gr

def greet(name):
    return f"Hello, {name}!"

demo = gr.Interface(fn=greet, inputs="text", outputs="text", title="Gradio App")

demo.launch(share=True)

